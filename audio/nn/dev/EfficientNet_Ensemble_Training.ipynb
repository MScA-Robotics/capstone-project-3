{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "from tensorflow_examples.lite.model_maker.core.data_util.image_dataloader import ImageClassifierDataLoader\n",
    "from tensorflow_examples.lite.model_maker.core.task import image_classifier\n",
    "from tensorflow_examples.lite.model_maker.core.task.model_spec import efficientnet_lite4_spec\n",
    "from tensorflow_examples.lite.model_maker.core.task.model_spec import ImageModelSpec\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# from matplotlib.pyplot import specgram\n",
    "# import librosa\n",
    "# import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion(y_true, y_pred, labels, perc = False):\n",
    "    conf = confusion_matrix(y_true, y_pred, labels)\n",
    "    conf = pd.DataFrame(conf, columns = labels)\n",
    "    conf['true_row_label'] = labels\n",
    "    conf.set_index('true_row_label', drop = True, inplace = True)\n",
    "    if perc:\n",
    "        conf = round(conf.div(conf.sum(axis=1), axis=0),2)\n",
    "    return conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_folder_images(folder):\n",
    "    folder = str(folder)\n",
    "    base_path = \"../downsampled/imagenet_structure/\"\n",
    "    return ImageClassifierDataLoader.from_folder(base_path + folder + \"/train\"), ImageClassifierDataLoader.from_folder(base_path + folder + \"/valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fit_submodel(image_folder_substring, epochs = 10, warmup_steps = 100, batch_size = 24):\n",
    "    train_data, valid_data = train_valid_folder_images(image_folder_substring)\n",
    "    return image_classifier.create(train_data, \n",
    "                                      model_spec=efficientnet_lite4_spec, \n",
    "                                      shuffle = True,\n",
    "                                      epochs = epochs, \n",
    "                                      batch_size = batch_size,\n",
    "                                      warmup_steps = warmup_steps, \n",
    "                                      validation_data = valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ensemble_model(model, path):\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    model.model.save(path)\n",
    "    model.export(path +'/model.tflite', path+'/labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# import shutil\n",
    "# from pathlib import Path  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data_path = Path('../downsampled/imagenet_structure/ensemble/') \n",
    "# submodels = {'engine-air-other': ['air_conditioner', 'engine_idling'], \n",
    "#              'drilling-jackhammer-other': ['drilling', 'jackhammer'] , \n",
    "#              'other': ['car_horn', 'children_playing', 'dog_bark', 'siren', 'street_music']}\n",
    "# labels  = ['air_conditioner','car_horn','children_playing',\n",
    "#            'dog_bark','drilling','engine_idling','gun_shot','jackhammer','siren','street_music']\n",
    "# def move_submodel_files(submodel_folder_name, submodel_class_list):\n",
    "#     if d in ['train', 'valid]':\n",
    "#         print(d)\n",
    "#         if not os.path.exists(data_path/submodel_folder_name/d/'other'):\n",
    "#             os.mkdir(data_path/submodel_folder_name/d/'other')\n",
    "#         for c in np.setdiff1d(labels,submodel_class_list,True).tolist():\n",
    "#             png_files = list(Path(data_path/submodel_folder_name/d/c).glob('*.png'))\n",
    "#             for f in png_files:\n",
    "#                 shutil.move(str(f), str(data_path/submodel_folder_name/d/'other'))\n",
    "#             os.rmdir(data_path/submodel_folder_name/d/c)\n",
    "\n",
    "# for k, v in submodels.items():\n",
    "#     print(k)\n",
    "#     move_submodel_files(k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Load image with size: 7859, num_label: 10, labels: air_conditioner, car_horn, children_playing, dog_bark, drilling, engine_idling, gun_shot, jackhammer, siren, street_music.\n",
      "INFO:tensorflow:Load image with size: 873, num_label: 10, labels: air_conditioner, car_horn, children_playing, dog_bark, drilling, engine_idling, gun_shot, jackhammer, siren, street_music.\n",
      "WARNING:tensorflow:From c:\\users\\audrey\\anaconda3\\envs\\robotics\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\audrey\\anaconda3\\envs\\robotics\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hub_keras_layer_v1v2 (HubKer (None, 1280)              11837936  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                12810     \n",
      "=================================================================\n",
      "Total params: 11,850,746\n",
      "Trainable params: 12,810\n",
      "Non-trainable params: 11,837,936\n",
      "_________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:Retraining the models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Retraining the models...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 327 steps, validate for 36 steps\n",
      "Epoch 1/50\n",
      "327/327 [==============================] - 146s 445ms/step - loss: 1.4889 - accuracy: 0.5766 - val_loss: 1.2508 - val_accuracy: 0.6875\n",
      "Epoch 2/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 1.2370 - accuracy: 0.6980 - val_loss: 1.1792 - val_accuracy: 0.7118\n",
      "Epoch 3/50\n",
      "327/327 [==============================] - 140s 429ms/step - loss: 1.1696 - accuracy: 0.7283 - val_loss: 1.1588 - val_accuracy: 0.7164\n",
      "Epoch 4/50\n",
      "327/327 [==============================] - 140s 429ms/step - loss: 1.1433 - accuracy: 0.7446 - val_loss: 1.1506 - val_accuracy: 0.7303\n",
      "Epoch 5/50\n",
      "327/327 [==============================] - 140s 429ms/step - loss: 1.1106 - accuracy: 0.7566 - val_loss: 1.1357 - val_accuracy: 0.7326\n",
      "Epoch 6/50\n",
      "327/327 [==============================] - 140s 429ms/step - loss: 1.0918 - accuracy: 0.7666 - val_loss: 1.1387 - val_accuracy: 0.7361\n",
      "Epoch 7/50\n",
      "327/327 [==============================] - 140s 429ms/step - loss: 1.0806 - accuracy: 0.7748 - val_loss: 1.1076 - val_accuracy: 0.7546\n",
      "Epoch 8/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 1.0733 - accuracy: 0.7794 - val_loss: 1.1320 - val_accuracy: 0.7500\n",
      "Epoch 9/50\n",
      "327/327 [==============================] - 140s 429ms/step - loss: 1.0583 - accuracy: 0.7886 - val_loss: 1.1235 - val_accuracy: 0.7350\n",
      "Epoch 10/50\n",
      "327/327 [==============================] - 140s 429ms/step - loss: 1.0509 - accuracy: 0.7826 - val_loss: 1.1099 - val_accuracy: 0.7488\n",
      "Epoch 11/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 1.0444 - accuracy: 0.7900 - val_loss: 1.1239 - val_accuracy: 0.7604\n",
      "Epoch 12/50\n",
      "327/327 [==============================] - 140s 429ms/step - loss: 1.0345 - accuracy: 0.7973 - val_loss: 1.1281 - val_accuracy: 0.7373\n",
      "Epoch 13/50\n",
      "327/327 [==============================] - 140s 429ms/step - loss: 1.0302 - accuracy: 0.7992 - val_loss: 1.1325 - val_accuracy: 0.7396\n",
      "Epoch 14/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 1.0300 - accuracy: 0.7937 - val_loss: 1.1340 - val_accuracy: 0.7338\n",
      "Epoch 15/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 1.0275 - accuracy: 0.7978 - val_loss: 1.1329 - val_accuracy: 0.7373\n",
      "Epoch 16/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 1.0182 - accuracy: 0.8061 - val_loss: 1.1234 - val_accuracy: 0.7442\n",
      "Epoch 17/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 1.0132 - accuracy: 0.8039 - val_loss: 1.1342 - val_accuracy: 0.7373\n",
      "Epoch 18/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 1.0119 - accuracy: 0.8077 - val_loss: 1.1308 - val_accuracy: 0.7396\n",
      "Epoch 19/50\n",
      "327/327 [==============================] - 140s 429ms/step - loss: 1.0059 - accuracy: 0.8089 - val_loss: 1.1239 - val_accuracy: 0.7581\n",
      "Epoch 20/50\n",
      "327/327 [==============================] - 140s 429ms/step - loss: 1.0050 - accuracy: 0.8112 - val_loss: 1.1149 - val_accuracy: 0.7500\n",
      "Epoch 21/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 1.0027 - accuracy: 0.8091 - val_loss: 1.1114 - val_accuracy: 0.7523\n",
      "Epoch 22/50\n",
      "327/327 [==============================] - 140s 429ms/step - loss: 1.0010 - accuracy: 0.8122 - val_loss: 1.1082 - val_accuracy: 0.7604\n",
      "Epoch 23/50\n",
      "327/327 [==============================] - 140s 429ms/step - loss: 0.9963 - accuracy: 0.8187 - val_loss: 1.1214 - val_accuracy: 0.7419\n",
      "Epoch 24/50\n",
      "327/327 [==============================] - 140s 429ms/step - loss: 0.9926 - accuracy: 0.8169 - val_loss: 1.1140 - val_accuracy: 0.7593\n",
      "Epoch 25/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 0.9895 - accuracy: 0.8188 - val_loss: 1.1028 - val_accuracy: 0.7662\n",
      "Epoch 26/50\n",
      "327/327 [==============================] - 140s 429ms/step - loss: 0.9851 - accuracy: 0.8202 - val_loss: 1.1031 - val_accuracy: 0.7662\n",
      "Epoch 27/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 0.9901 - accuracy: 0.8170 - val_loss: 1.1000 - val_accuracy: 0.7720\n",
      "Epoch 28/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 0.9857 - accuracy: 0.8222 - val_loss: 1.1199 - val_accuracy: 0.7720\n",
      "Epoch 29/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 0.9846 - accuracy: 0.8188 - val_loss: 1.0963 - val_accuracy: 0.7778\n",
      "Epoch 30/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 0.9848 - accuracy: 0.8180 - val_loss: 1.1030 - val_accuracy: 0.7604\n",
      "Epoch 31/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 0.9794 - accuracy: 0.8211 - val_loss: 1.1118 - val_accuracy: 0.7512\n",
      "Epoch 32/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 0.9801 - accuracy: 0.8221 - val_loss: 1.0900 - val_accuracy: 0.7674\n",
      "Epoch 33/50\n",
      "327/327 [==============================] - 140s 429ms/step - loss: 0.9783 - accuracy: 0.8268 - val_loss: 1.0989 - val_accuracy: 0.7616\n",
      "Epoch 34/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 0.9785 - accuracy: 0.8258 - val_loss: 1.1272 - val_accuracy: 0.7373\n",
      "Epoch 35/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 0.9778 - accuracy: 0.8233 - val_loss: 1.1068 - val_accuracy: 0.7789\n",
      "Epoch 36/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 0.9768 - accuracy: 0.8272 - val_loss: 1.1091 - val_accuracy: 0.7627\n",
      "Epoch 37/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 0.9710 - accuracy: 0.8310 - val_loss: 1.1191 - val_accuracy: 0.7465\n",
      "Epoch 38/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 0.9722 - accuracy: 0.8275 - val_loss: 1.1289 - val_accuracy: 0.7465\n",
      "Epoch 39/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 0.9677 - accuracy: 0.8299 - val_loss: 1.1105 - val_accuracy: 0.7766\n",
      "Epoch 40/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 0.9693 - accuracy: 0.8258 - val_loss: 1.1066 - val_accuracy: 0.7627\n",
      "Epoch 41/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 0.9692 - accuracy: 0.8303 - val_loss: 1.1082 - val_accuracy: 0.7755\n",
      "Epoch 42/50\n",
      "327/327 [==============================] - 140s 429ms/step - loss: 0.9669 - accuracy: 0.8315 - val_loss: 1.1068 - val_accuracy: 0.7755\n",
      "Epoch 43/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 0.9674 - accuracy: 0.8321 - val_loss: 1.1093 - val_accuracy: 0.7801\n",
      "Epoch 44/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 0.9626 - accuracy: 0.8336 - val_loss: 1.1023 - val_accuracy: 0.7731\n",
      "Epoch 45/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 0.9652 - accuracy: 0.8310 - val_loss: 1.1160 - val_accuracy: 0.7674\n",
      "Epoch 46/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 0.9578 - accuracy: 0.8342 - val_loss: 1.1068 - val_accuracy: 0.7801\n",
      "Epoch 47/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 0.9623 - accuracy: 0.8290 - val_loss: 1.1082 - val_accuracy: 0.7766\n",
      "Epoch 48/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 0.9606 - accuracy: 0.8314 - val_loss: 1.1006 - val_accuracy: 0.7674\n",
      "Epoch 49/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 0.9575 - accuracy: 0.8368 - val_loss: 1.1058 - val_accuracy: 0.7824\n",
      "Epoch 50/50\n",
      "327/327 [==============================] - 140s 428ms/step - loss: 0.9573 - accuracy: 0.8356 - val_loss: 1.0984 - val_accuracy: 0.7812\n"
     ]
    }
   ],
   "source": [
    "model_main = create_fit_submodel('ensemble/main_model', epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/main_model_e50\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/main_model_e50\\assets\n"
     ]
    }
   ],
   "source": [
    "model_name = 'main_model_e50'\n",
    "os.mkdir('./models/ensemble/'+model_name)\n",
    "model_main.model.save('models/ensemble/' + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Export to tflite model in ./models/ensemble/main_model_e50/model.tflite.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Export to tflite model in ./models/ensemble/main_model_e50/model.tflite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saved labels in ./models/ensemble/main_model_e50/labels.txt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saved labels in ./models/ensemble/main_model_e50/labels.txt.\n"
     ]
    }
   ],
   "source": [
    "model_path_prefix = './models/ensemble/'+ model_name \n",
    "model_main.export(model_path_prefix+'/model.tflite', model_path_prefix+'/labels.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Test Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "def folder_data_generator(folder_path, \n",
    "                          batch_size = 24, \n",
    "                          input_image_shape = (300,300),\n",
    "                          shuffle = True, \n",
    "                          seed = 42):\n",
    "    \"\"\"Generates an ImageDataGenerator that is scaled by (1/255) and\n",
    "        resized to the required input shape.\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "    folder_path: path to directory containing images organized in class-named subdirectories\n",
    "        Example: '../downsampled/imagenet_structure/ensemble/model-main/train/'\n",
    "    hparams (dataclas):  Hyperparameters with minimum requirements:\n",
    "        .input_image_shape (tuple): image shape required by model, to be resized\n",
    "        .batch_size (int): batch size for generator\n",
    "    shuffe (bool): if images should be shuffled.  Defaults to True\n",
    "    seed (int): seed for random shuffle. Defaults to 42\n",
    "    \n",
    "    Assumes class_mode = 'categorical' and color_mode = 'rgb' for images.\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    ImageDataGenerator object\n",
    "    \"\"\"\n",
    "    # ex: '../downsampled/imagenet_structure/1/valid/'\n",
    "    datagen = ImageDataGenerator(rescale = 1.0/255.0)\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory = folder_path,\n",
    "        target_size = input_image_shape, \n",
    "        class_mode = 'categorical', \n",
    "        color_mode = 'rgb',\n",
    "        batch_size = batch_size,\n",
    "        shuffle = shuffle, \n",
    "        seed = seed)\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## air-drill-engine-jackhammer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Load image with size: 3584, num_label: 4, labels: air_conditioner, drilling, engine_idling, jackhammer.\n",
      "INFO:tensorflow:Load image with size: 416, num_label: 4, labels: air_conditioner, drilling, engine_idling, jackhammer.\n",
      "WARNING:tensorflow:From c:\\users\\audrey\\anaconda3\\envs\\robotics\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\audrey\\anaconda3\\envs\\robotics\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hub_keras_layer_v1v2 (HubKer (None, 1280)              11837936  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 5124      \n",
      "=================================================================\n",
      "Total params: 11,843,060\n",
      "Trainable params: 5,124\n",
      "Non-trainable params: 11,837,936\n",
      "_________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:Retraining the models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Retraining the models...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 149 steps, validate for 17 steps\n",
      "Epoch 1/10\n",
      "149/149 [==============================] - 75s 502ms/step - loss: 1.0748 - accuracy: 0.5959 - val_loss: 0.9727 - val_accuracy: 0.6765\n",
      "Epoch 2/10\n",
      "149/149 [==============================] - 64s 432ms/step - loss: 0.9063 - accuracy: 0.7078 - val_loss: 0.9162 - val_accuracy: 0.7108\n",
      "Epoch 3/10\n",
      "149/149 [==============================] - 64s 428ms/step - loss: 0.8523 - accuracy: 0.7408 - val_loss: 0.8980 - val_accuracy: 0.7132\n",
      "Epoch 4/10\n",
      "149/149 [==============================] - 64s 427ms/step - loss: 0.8310 - accuracy: 0.7550 - val_loss: 0.8906 - val_accuracy: 0.7157\n",
      "Epoch 5/10\n",
      "149/149 [==============================] - 64s 427ms/step - loss: 0.8017 - accuracy: 0.7757 - val_loss: 0.9020 - val_accuracy: 0.6887\n",
      "Epoch 6/10\n",
      "149/149 [==============================] - 64s 427ms/step - loss: 0.7931 - accuracy: 0.7771 - val_loss: 0.8882 - val_accuracy: 0.6961\n",
      "Epoch 7/10\n",
      "149/149 [==============================] - 64s 427ms/step - loss: 0.7810 - accuracy: 0.7816 - val_loss: 0.8697 - val_accuracy: 0.7279\n",
      "Epoch 8/10\n",
      "149/149 [==============================] - 64s 427ms/step - loss: 0.7713 - accuracy: 0.7925 - val_loss: 0.8825 - val_accuracy: 0.7108\n",
      "Epoch 9/10\n",
      "149/149 [==============================] - 64s 428ms/step - loss: 0.7655 - accuracy: 0.7894 - val_loss: 0.8568 - val_accuracy: 0.7426\n",
      "Epoch 10/10\n",
      "149/149 [==============================] - 64s 429ms/step - loss: 0.7456 - accuracy: 0.8059 - val_loss: 0.8467 - val_accuracy: 0.7304\n"
     ]
    }
   ],
   "source": [
    "model_adej = create_fit_submodel('ensemble/air-drill-engine-jackhammer', epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ensemble/air-drill-engine-jackhammer_e10\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ensemble/air-drill-engine-jackhammer_e10\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Export to tflite model in ./models/ensemble/air-drill-engine-jackhammer_e10/air-drill-engine-jackhammer_e10.tflite.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Export to tflite model in ./models/ensemble/air-drill-engine-jackhammer_e10/air-drill-engine-jackhammer_e10.tflite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saved labels in ./models/ensemble/air-drill-engine-jackhammer_e10/air-drill-engine-jackhammer_e10_labels.txt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saved labels in ./models/ensemble/air-drill-engine-jackhammer_e10/air-drill-engine-jackhammer_e10_labels.txt.\n"
     ]
    }
   ],
   "source": [
    "save_ensemble_model(model_adej,'air-drill-engine-jackhammer_e10','./models/ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Load image with size: 873, num_label: 3, labels: drilling, jackhammer, other.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Load image with size: 873, num_label: 3, labels: drilling, jackhammer, other.\n"
     ]
    }
   ],
   "source": [
    "def valid_folder_images(folder):\n",
    "    folder = str(folder)\n",
    "    base_path = \"../downsampled/imagenet_structure/\"\n",
    "    return ImageClassifierDataLoader.from_folder(base_path + folder + \"/valid\")\n",
    "\n",
    "valid_data = valid_folder_images(\"ensemble/drilling-jackhammer-other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_predicts = model_djo.predict_top_k(valid_data)\n",
    "valid_label = [valid_data.index_to_label[label.numpy()] for i, (image, label) in enumerate(valid_data.dataset.take(len(valid_predicts)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_predict_label = [i[0][0] for i in valid_predicts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e20\n",
    "print(classification_report(y_true = valid_label, y_pred = valid_predict_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion(valid_label, valid_predict_label, valid_data.index_to_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## horn-children-dog-gun-siren-music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = 'horn-children-dog-gun-siren-music'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Load image with size: 4275, num_label: 6, labels: car_horn, children_playing, dog_bark, gun_shot, siren, street_music.\n",
      "INFO:tensorflow:Load image with size: 457, num_label: 6, labels: car_horn, children_playing, dog_bark, gun_shot, siren, street_music.\n",
      "WARNING:tensorflow:From c:\\users\\audrey\\anaconda3\\envs\\robotics\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\audrey\\anaconda3\\envs\\robotics\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hub_keras_layer_v1v2 (HubKer (None, 1280)              11837936  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 7686      \n",
      "=================================================================\n",
      "Total params: 11,845,622\n",
      "Trainable params: 7,686\n",
      "Non-trainable params: 11,837,936\n",
      "_________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:Retraining the models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Retraining the models...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 178 steps, validate for 19 steps\n",
      "Epoch 1/20\n",
      "178/178 [==============================] - 85s 479ms/step - loss: 1.0856 - accuracy: 0.6821 - val_loss: 0.7710 - val_accuracy: 0.8487\n",
      "Epoch 2/20\n",
      "178/178 [==============================] - 76s 427ms/step - loss: 0.8684 - accuracy: 0.7980 - val_loss: 0.7486 - val_accuracy: 0.8531\n",
      "Epoch 3/20\n",
      "178/178 [==============================] - 76s 427ms/step - loss: 0.8226 - accuracy: 0.8287 - val_loss: 0.7283 - val_accuracy: 0.8772\n",
      "Epoch 4/20\n",
      "178/178 [==============================] - 76s 427ms/step - loss: 0.8047 - accuracy: 0.8397 - val_loss: 0.7304 - val_accuracy: 0.8728\n",
      "Epoch 5/20\n",
      "178/178 [==============================] - 76s 427ms/step - loss: 0.7869 - accuracy: 0.8497 - val_loss: 0.7269 - val_accuracy: 0.8662\n",
      "Epoch 6/20\n",
      "178/178 [==============================] - 76s 427ms/step - loss: 0.7756 - accuracy: 0.8481 - val_loss: 0.7167 - val_accuracy: 0.8772\n",
      "Epoch 7/20\n",
      "178/178 [==============================] - 77s 430ms/step - loss: 0.7712 - accuracy: 0.8535 - val_loss: 0.7193 - val_accuracy: 0.8706\n",
      "Epoch 8/20\n",
      "178/178 [==============================] - 77s 434ms/step - loss: 0.7570 - accuracy: 0.8617 - val_loss: 0.7227 - val_accuracy: 0.8728\n",
      "Epoch 9/20\n",
      "178/178 [==============================] - 77s 434ms/step - loss: 0.7586 - accuracy: 0.8649 - val_loss: 0.7207 - val_accuracy: 0.8750\n",
      "Epoch 10/20\n",
      "178/178 [==============================] - 86s 484ms/step - loss: 0.7436 - accuracy: 0.8624 - val_loss: 0.7133 - val_accuracy: 0.8772\n",
      "Epoch 11/20\n",
      "178/178 [==============================] - 76s 427ms/step - loss: 0.7450 - accuracy: 0.8633 - val_loss: 0.7187 - val_accuracy: 0.8838\n",
      "Epoch 12/20\n",
      "178/178 [==============================] - 76s 427ms/step - loss: 0.7379 - accuracy: 0.8736 - val_loss: 0.7211 - val_accuracy: 0.8750\n",
      "Epoch 13/20\n",
      "178/178 [==============================] - 76s 428ms/step - loss: 0.7380 - accuracy: 0.8720 - val_loss: 0.7093 - val_accuracy: 0.8991\n",
      "Epoch 14/20\n",
      "178/178 [==============================] - 76s 428ms/step - loss: 0.7353 - accuracy: 0.8734 - val_loss: 0.7067 - val_accuracy: 0.8904\n",
      "Epoch 15/20\n",
      "178/178 [==============================] - 76s 428ms/step - loss: 0.7254 - accuracy: 0.8809 - val_loss: 0.7113 - val_accuracy: 0.8860\n",
      "Epoch 16/20\n",
      "178/178 [==============================] - 76s 428ms/step - loss: 0.7274 - accuracy: 0.8773 - val_loss: 0.7098 - val_accuracy: 0.8904\n",
      "Epoch 17/20\n",
      "178/178 [==============================] - 76s 427ms/step - loss: 0.7214 - accuracy: 0.8762 - val_loss: 0.7026 - val_accuracy: 0.8904\n",
      "Epoch 18/20\n",
      "178/178 [==============================] - 76s 428ms/step - loss: 0.7215 - accuracy: 0.8844 - val_loss: 0.7041 - val_accuracy: 0.8860\n",
      "Epoch 19/20\n",
      "178/178 [==============================] - 76s 428ms/step - loss: 0.7218 - accuracy: 0.8823 - val_loss: 0.7026 - val_accuracy: 0.8947\n",
      "Epoch 20/20\n",
      "178/178 [==============================] - 76s 428ms/step - loss: 0.7162 - accuracy: 0.8816 - val_loss: 0.7028 - val_accuracy: 0.8882\n"
     ]
    }
   ],
   "source": [
    "model_adej = create_fit_submodel('ensemble/' + group, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ensemble/horn-children-dog-gun-siren-music\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ensemble/horn-children-dog-gun-siren-music\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Export to tflite model in ./models/ensemble/horn-children-dog-gun-siren-music/model.tflite.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Export to tflite model in ./models/ensemble/horn-children-dog-gun-siren-music/model.tflite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saved labels in ./models/ensemble/horn-children-dog-gun-siren-music/labels.txt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saved labels in ./models/ensemble/horn-children-dog-gun-siren-music/labels.txt.\n"
     ]
    }
   ],
   "source": [
    "save_ensemble_model(model_adej, './models/ensemble/'+group)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
