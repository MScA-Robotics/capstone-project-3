{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "from tensorflow_examples.lite.model_maker.core.data_util.image_dataloader import ImageClassifierDataLoader\n",
    "from tensorflow_examples.lite.model_maker.core.task import image_classifier\n",
    "from tensorflow_examples.lite.model_maker.core.task.model_spec import efficientnet_lite2_spec, efficientnet_lite4_spec\n",
    "from tensorflow_examples.lite.model_maker.core.task.model_spec import ImageModelSpec\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# from matplotlib.pyplot import specgram\n",
    "# import librosa\n",
    "# import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_fold_images(fold):\n",
    "    fold = str(fold)\n",
    "    base_path = \"../downsampled/imagenet_structure/\"\n",
    "    return ImageClassifierDataLoader.from_folder(base_path + folder + \"/train\"), ImageClassifierDataLoader.from_folder(base_path + fold + \"/valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Load image with size: 7859, num_label: 10, labels: air_conditioner, car_horn, children_playing, dog_bark, drilling, engine_idling, gun_shot, jackhammer, siren, street_music.\n",
      "INFO:tensorflow:Load image with size: 873, num_label: 10, labels: air_conditioner, car_horn, children_playing, dog_bark, drilling, engine_idling, gun_shot, jackhammer, siren, street_music.\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data = train_valid_fold_images('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\audrey\\anaconda3\\envs\\robotics\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\audrey\\anaconda3\\envs\\robotics\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hub_keras_layer_v1v2 (HubKer (None, 1280)              4869168   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                12810     \n",
      "=================================================================\n",
      "Total params: 4,881,978\n",
      "Trainable params: 12,810\n",
      "Non-trainable params: 4,869,168\n",
      "_________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:Retraining the models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Retraining the models...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 245 steps\n",
      "Epoch 1/5\n",
      "245/245 [==============================] - 63s 258ms/step - loss: 1.5394 - accuracy: 0.5468\n",
      "Epoch 2/5\n",
      "245/245 [==============================] - 57s 233ms/step - loss: 1.2768 - accuracy: 0.6798\n",
      "Epoch 3/5\n",
      "245/245 [==============================] - 57s 232ms/step - loss: 1.2174 - accuracy: 0.7033\n",
      "Epoch 4/5\n",
      "245/245 [==============================] - 57s 235ms/step - loss: 1.1811 - accuracy: 0.7226\n",
      "Epoch 5/5\n",
      "245/245 [==============================] - 57s 233ms/step - loss: 1.1576 - accuracy: 0.7341\n"
     ]
    }
   ],
   "source": [
    "# Customize the pre-trained TensorFlow model\n",
    "model = image_classifier.create(train_data, model_spec=efficientnet_lite2_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 7s 257ms/step - loss: 1.2190 - accuracy: 0.7010\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lite4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hub_keras_layer_v1v2_2 (HubK (None, 1280)              11837936  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                12810     \n",
      "=================================================================\n",
      "Total params: 11,850,746\n",
      "Trainable params: 12,810\n",
      "Non-trainable params: 11,837,936\n",
      "_________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:Retraining the models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Retraining the models...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 245 steps\n",
      "Epoch 1/5\n",
      "245/245 [==============================] - 128s 523ms/step - loss: 1.5506 - accuracy: 0.5527\n",
      "Epoch 2/5\n",
      "245/245 [==============================] - 124s 507ms/step - loss: 1.2656 - accuracy: 0.6811\n",
      "Epoch 3/5\n",
      "245/245 [==============================] - 125s 512ms/step - loss: 1.2084 - accuracy: 0.7066\n",
      "Epoch 4/5\n",
      "245/245 [==============================] - 126s 513ms/step - loss: 1.1647 - accuracy: 0.7298\n",
      "Epoch 5/5\n",
      "245/245 [==============================] - 125s 511ms/step - loss: 1.1386 - accuracy: 0.7413\n"
     ]
    }
   ],
   "source": [
    "# Customize the pre-trained TensorFlow model\n",
    "model_lite4 = image_classifier.create(train_data, \n",
    "                                      model_spec=efficientnet_lite4_spec, warmup_steps = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 16s 558ms/step - loss: 1.1503 - accuracy: 0.7285\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_lite4.evaluate(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Export to tflite model in UrbanEfficientNetLite4_out1_e5_noshuffle.tflite.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Export to tflite model in UrbanEfficientNetLite4_out1_e5_noshuffle.tflite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saved labels in urban_label_lite4.txt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saved labels in urban_label_lite4.txt.\n"
     ]
    }
   ],
   "source": [
    "model_lite4.export('UrbanEfficientNetLite4_out1_e5_noshuffle.tflite', 'urban_label_lite4.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\audrey\\anaconda3\\envs\\robotics\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\audrey\\anaconda3\\envs\\robotics\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hub_keras_layer_v1v2 (HubKer (None, 1280)              11837936  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                12810     \n",
      "=================================================================\n",
      "Total params: 11,850,746\n",
      "Trainable params: 12,810\n",
      "Non-trainable params: 11,837,936\n",
      "_________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:Retraining the models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Retraining the models...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 327 steps\n",
      "Epoch 1/8\n",
      "327/327 [==============================] - 133s 406ms/step - loss: 1.4857 - accuracy: 0.5833\n",
      "Epoch 2/8\n",
      "327/327 [==============================] - 126s 386ms/step - loss: 1.2290 - accuracy: 0.7006\n",
      "Epoch 3/8\n",
      "327/327 [==============================] - 126s 387ms/step - loss: 1.1707 - accuracy: 0.7325\n",
      "Epoch 4/8\n",
      "327/327 [==============================] - 124s 380ms/step - loss: 1.1391 - accuracy: 0.7457\n",
      "Epoch 5/8\n",
      "327/327 [==============================] - 125s 383ms/step - loss: 1.1106 - accuracy: 0.7578\n",
      "Epoch 6/8\n",
      "327/327 [==============================] - 126s 384ms/step - loss: 1.0922 - accuracy: 0.7659\n",
      "Epoch 7/8\n",
      "327/327 [==============================] - 124s 379ms/step - loss: 1.0813 - accuracy: 0.7718\n",
      "Epoch 8/8\n",
      "327/327 [==============================] - 124s 379ms/step - loss: 1.0628 - accuracy: 0.7840\n"
     ]
    }
   ],
   "source": [
    "model_lite4 = image_classifier.create(train_data, \n",
    "                                      model_spec=efficientnet_lite4_spec, \n",
    "                                      shuffle = True,\n",
    "                                      batch_size = 24,\n",
    "                                      warmup_steps = 100, \n",
    "                                      epochs = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 17s 590ms/step - loss: 1.1026 - accuracy: 0.7675\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_lite4.evaluate(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Export to tflite model in ./models/UrbanEfficientNetLite4_val1_e8_shuffle.tflite.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Export to tflite model in ./models/UrbanEfficientNetLite4_val1_e8_shuffle.tflite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saved labels in ./models/UrbanEfficientNetLite4_val1_e8_shuffle_labels.txt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saved labels in ./models/UrbanEfficientNetLite4_val1_e8_shuffle_labels.txt.\n"
     ]
    }
   ],
   "source": [
    "model_path_prefix = './models/UrbanEfficientNetLite4_val1_e8_shuffle'\n",
    "model_lite4.export(model_path_prefix+'.tflite', model_path_prefix+'_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = model_lite4._gen_dataset(valid_data, 24, is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 300, 300, 3), (None, 10)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Sequential.predict_classes of <tensorflow.python.keras.engine.sequential.Sequential object at 0x0000021F97FFCE48>>\n"
     ]
    }
   ],
   "source": [
    "model_lite4.model.predict_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  def predict_classes(self, x, batch_size=32, verbose=0):\n",
      "    \"\"\"Generate class predictions for the input samples.\n",
      "\n",
      "    The input samples are processed batch by batch.\n",
      "\n",
      "    Arguments:\n",
      "        x: input data, as a Numpy array or list of Numpy arrays\n",
      "            (if the model has multiple inputs).\n",
      "        batch_size: integer.\n",
      "        verbose: verbosity mode, 0 or 1.\n",
      "\n",
      "    Returns:\n",
      "        A numpy array of class predictions.\n",
      "    \"\"\"\n",
      "    proba = self.predict(x, batch_size=batch_size, verbose=verbose)\n",
      "    if proba.shape[-1] > 1:\n",
      "      return proba.argmax(axis=-1)\n",
      "    else:\n",
      "      return (proba > 0.5).astype('int32')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(model_lite4.model.predict_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_predicts = model_lite4.predict_top_k(valid_data)\n",
    "valid_label = [valid_data.index_to_label[label.numpy()] for i, (image, label) in enumerate(valid_data.dataset.take(len(predicts)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_predict_label = [i[0][0] for i in valid_predicts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      " air_conditioner       0.60      0.74      0.66       100\n",
      "        car_horn       0.91      0.81      0.85        36\n",
      "children_playing       0.77      0.87      0.82       100\n",
      "        dog_bark       0.82      0.86      0.84       100\n",
      "        drilling       0.64      0.54      0.58       100\n",
      "   engine_idling       0.93      0.53      0.68        96\n",
      "        gun_shot       0.70      0.91      0.79        35\n",
      "      jackhammer       0.89      0.86      0.87       120\n",
      "           siren       0.79      0.90      0.84        86\n",
      "    street_music       0.77      0.77      0.77       100\n",
      "\n",
      "        accuracy                           0.77       873\n",
      "       macro avg       0.78      0.78      0.77       873\n",
      "    weighted avg       0.78      0.77      0.76       873\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true = valid_true_id, y_pred = valid_predict_id, labels = valid_data.index_to_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_conditioner</th>\n",
       "      <th>car_horn</th>\n",
       "      <th>children_playing</th>\n",
       "      <th>dog_bark</th>\n",
       "      <th>drilling</th>\n",
       "      <th>engine_idling</th>\n",
       "      <th>gun_shot</th>\n",
       "      <th>jackhammer</th>\n",
       "      <th>siren</th>\n",
       "      <th>street_music</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_row_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>air_conditioner</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car_horn</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>children_playing</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog_bark</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drilling</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engine_idling</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gun_shot</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jackhammer</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>siren</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>street_music</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  air_conditioner  car_horn  children_playing  dog_bark  \\\n",
       "true_row_label                                                            \n",
       "air_conditioner              0.74      0.00              0.03      0.06   \n",
       "car_horn                     0.00      0.81              0.00      0.03   \n",
       "children_playing             0.00      0.00              0.87      0.06   \n",
       "dog_bark                     0.00      0.01              0.01      0.86   \n",
       "drilling                     0.14      0.00              0.09      0.02   \n",
       "engine_idling                0.31      0.00              0.00      0.03   \n",
       "gun_shot                     0.00      0.00              0.00      0.00   \n",
       "jackhammer                   0.00      0.01              0.00      0.01   \n",
       "siren                        0.01      0.00              0.07      0.00   \n",
       "street_music                 0.04      0.01              0.07      0.00   \n",
       "\n",
       "                  drilling  engine_idling  gun_shot  jackhammer  siren  \\\n",
       "true_row_label                                                           \n",
       "air_conditioner       0.04           0.02      0.00        0.04   0.04   \n",
       "car_horn              0.00           0.00      0.06        0.00   0.08   \n",
       "children_playing      0.00           0.00      0.00        0.00   0.00   \n",
       "dog_bark              0.01           0.00      0.05        0.00   0.03   \n",
       "drilling              0.54           0.00      0.07        0.00   0.05   \n",
       "engine_idling         0.04           0.53      0.00        0.07   0.01   \n",
       "gun_shot              0.09           0.00      0.91        0.00   0.00   \n",
       "jackhammer            0.12           0.01      0.00        0.86   0.00   \n",
       "siren                 0.02           0.00      0.00        0.00   0.90   \n",
       "street_music          0.03           0.01      0.00        0.02   0.05   \n",
       "\n",
       "                  street_music  \n",
       "true_row_label                  \n",
       "air_conditioner           0.03  \n",
       "car_horn                  0.03  \n",
       "children_playing          0.07  \n",
       "dog_bark                  0.03  \n",
       "drilling                  0.09  \n",
       "engine_idling             0.00  \n",
       "gun_shot                  0.00  \n",
       "jackhammer                0.00  \n",
       "siren                     0.00  \n",
       "street_music              0.77  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = confusion_matrix(y_true = valid_label, y_pred = valid_predict_label, labels = valid_data.index_to_label)\n",
    "conf = pd.DataFrame(conf, columns = valid_data.index_to_label)\n",
    "conf['true_row_label'] = valid_data.index_to_label\n",
    "conf.set_index('true_row_label', drop = True, inplace = True)\n",
    "conf_perc = round(conf.div(conf.sum(axis=1), axis=0),2)\n",
    "conf_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(data):\n",
    "    predict = model_lite4.predict_top_k(data)\n",
    "    return [i[0][0] for i in predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      " air_conditioner       0.61      0.76      0.68       100\n",
      "        car_horn       0.94      0.89      0.91        36\n",
      "children_playing       0.79      0.89      0.84       100\n",
      "        dog_bark       0.79      0.93      0.86       100\n",
      "        drilling       0.71      0.39      0.50       100\n",
      "   engine_idling       0.92      0.51      0.66        96\n",
      "        gun_shot       0.86      0.89      0.87        35\n",
      "      jackhammer       0.81      0.90      0.85       120\n",
      "           siren       0.77      0.88      0.82        86\n",
      "    street_music       0.74      0.81      0.78       100\n",
      "\n",
      "        accuracy                           0.77       873\n",
      "       macro avg       0.80      0.78      0.78       873\n",
      "    weighted avg       0.78      0.77      0.76       873\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#e12\n",
    "print(classification_report(y_true = valid_label, y_pred = valid_predict_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hub_keras_layer_v1v2_1 (HubK (None, 1280)              11837936  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                12810     \n",
      "=================================================================\n",
      "Total params: 11,850,746\n",
      "Trainable params: 12,810\n",
      "Non-trainable params: 11,837,936\n",
      "_________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:Retraining the models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Retraining the models...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 327 steps\n",
      "Epoch 1/20\n",
      "327/327 [==============================] - 145s 444ms/step - loss: 1.4949 - accuracy: 0.5801\n",
      "Epoch 2/20\n",
      "327/327 [==============================] - 128s 391ms/step - loss: 1.2322 - accuracy: 0.7003\n",
      "Epoch 3/20\n",
      "327/327 [==============================] - 128s 390ms/step - loss: 1.1716 - accuracy: 0.7288\n",
      "Epoch 4/20\n",
      "327/327 [==============================] - 129s 396ms/step - loss: 1.1370 - accuracy: 0.7449\n",
      "Epoch 5/20\n",
      "327/327 [==============================] - 132s 405ms/step - loss: 1.1079 - accuracy: 0.7627\n",
      "Epoch 6/20\n",
      "327/327 [==============================] - 134s 411ms/step - loss: 1.0889 - accuracy: 0.7708\n",
      "Epoch 7/20\n",
      "327/327 [==============================] - 131s 400ms/step - loss: 1.0822 - accuracy: 0.7742\n",
      "Epoch 8/20\n",
      "327/327 [==============================] - 131s 400ms/step - loss: 1.0670 - accuracy: 0.7826\n",
      "Epoch 9/20\n",
      "327/327 [==============================] - 129s 395ms/step - loss: 1.0560 - accuracy: 0.7882\n",
      "Epoch 10/20\n",
      "327/327 [==============================] - 130s 397ms/step - loss: 1.0501 - accuracy: 0.7834\n",
      "Epoch 11/20\n",
      "327/327 [==============================] - 130s 399ms/step - loss: 1.0435 - accuracy: 0.7878\n",
      "Epoch 12/20\n",
      "327/327 [==============================] - 129s 394ms/step - loss: 1.0308 - accuracy: 0.7984\n",
      "Epoch 13/20\n",
      "327/327 [==============================] - 130s 396ms/step - loss: 1.0376 - accuracy: 0.7926\n",
      "Epoch 14/20\n",
      "327/327 [==============================] - 130s 398ms/step - loss: 1.0292 - accuracy: 0.8005\n",
      "Epoch 15/20\n",
      "327/327 [==============================] - 129s 394ms/step - loss: 1.0234 - accuracy: 0.7983\n",
      "Epoch 16/20\n",
      "327/327 [==============================] - 129s 396ms/step - loss: 1.0248 - accuracy: 0.8011\n",
      "Epoch 17/20\n",
      "327/327 [==============================] - 126s 386ms/step - loss: 1.0142 - accuracy: 0.8057\n",
      "Epoch 18/20\n",
      "327/327 [==============================] - 131s 400ms/step - loss: 1.0099 - accuracy: 0.8050\n",
      "Epoch 19/20\n",
      "327/327 [==============================] - 128s 391ms/step - loss: 1.0105 - accuracy: 0.8052\n",
      "Epoch 20/20\n",
      "327/327 [==============================] - 131s 402ms/step - loss: 1.0062 - accuracy: 0.8061\n"
     ]
    }
   ],
   "source": [
    "model_lite4 = image_classifier.create(train_data, \n",
    "                                      model_spec=efficientnet_lite4_spec, \n",
    "                                      shuffle = True,\n",
    "                                      batch_size = 24,\n",
    "                                      warmup_steps = 100, \n",
    "                                      epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 15s 523ms/step - loss: 1.0896 - accuracy: 0.7755\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_lite4.evaluate(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Export to tflite model in ./models/UrbanEfficientNetLite4_val1_e20_shuffle.tflite.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Export to tflite model in ./models/UrbanEfficientNetLite4_val1_e20_shuffle.tflite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saved labels in ./models/UrbanEfficientNetLite4_val1_e20_shuffle_labels.txt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saved labels in ./models/UrbanEfficientNetLite4_val1_e20_shuffle_labels.txt.\n"
     ]
    }
   ],
   "source": [
    "model_path_prefix = './models/UrbanEfficientNetLite4_val1_e20_shuffle'\n",
    "model_lite4.export(model_path_prefix+'.tflite', model_path_prefix+'_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_predicts = model_lite4.predict_top_k(valid_data)\n",
    "valid_label = [valid_data.index_to_label[label.numpy()] for i, (image, label) in enumerate(valid_data.dataset.take(len(valid_predicts)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_predict_label = [i[0][0] for i in valid_predicts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      " air_conditioner       0.57      0.81      0.67       100\n",
      "        car_horn       0.94      0.92      0.93        36\n",
      "children_playing       0.76      0.94      0.84       100\n",
      "        dog_bark       0.86      0.91      0.88       100\n",
      "        drilling       0.61      0.51      0.56       100\n",
      "   engine_idling       0.93      0.57      0.71        96\n",
      "        gun_shot       0.76      0.89      0.82        35\n",
      "      jackhammer       0.88      0.78      0.83       120\n",
      "           siren       0.78      0.90      0.83        86\n",
      "    street_music       0.90      0.70      0.79       100\n",
      "\n",
      "        accuracy                           0.78       873\n",
      "       macro avg       0.80      0.79      0.79       873\n",
      "    weighted avg       0.79      0.78      0.77       873\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#e20\n",
    "print(classification_report(y_true = valid_label, y_pred = valid_predict_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_conditioner</th>\n",
       "      <th>car_horn</th>\n",
       "      <th>children_playing</th>\n",
       "      <th>dog_bark</th>\n",
       "      <th>drilling</th>\n",
       "      <th>engine_idling</th>\n",
       "      <th>gun_shot</th>\n",
       "      <th>jackhammer</th>\n",
       "      <th>siren</th>\n",
       "      <th>street_music</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_row_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>air_conditioner</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car_horn</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>children_playing</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog_bark</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drilling</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engine_idling</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gun_shot</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jackhammer</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>siren</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>street_music</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  air_conditioner  car_horn  children_playing  dog_bark  \\\n",
       "true_row_label                                                            \n",
       "air_conditioner              0.81      0.00              0.03      0.05   \n",
       "car_horn                     0.00      0.92              0.00      0.06   \n",
       "children_playing             0.00      0.00              0.94      0.04   \n",
       "dog_bark                     0.00      0.00              0.02      0.91   \n",
       "drilling                     0.19      0.00              0.10      0.02   \n",
       "engine_idling                0.29      0.00              0.00      0.01   \n",
       "gun_shot                     0.00      0.00              0.00      0.00   \n",
       "jackhammer                   0.05      0.01              0.01      0.01   \n",
       "siren                        0.01      0.00              0.07      0.00   \n",
       "street_music                 0.06      0.01              0.08      0.00   \n",
       "\n",
       "                  drilling  engine_idling  gun_shot  jackhammer  siren  \\\n",
       "true_row_label                                                           \n",
       "air_conditioner       0.04           0.00      0.00        0.02   0.05   \n",
       "car_horn              0.00           0.00      0.03        0.00   0.00   \n",
       "children_playing      0.00           0.00      0.00        0.00   0.00   \n",
       "dog_bark              0.00           0.00      0.01        0.00   0.04   \n",
       "drilling              0.51           0.00      0.08        0.01   0.05   \n",
       "engine_idling         0.03           0.57      0.00        0.08   0.01   \n",
       "gun_shot              0.11           0.00      0.89        0.00   0.00   \n",
       "jackhammer            0.11           0.03      0.00        0.78   0.00   \n",
       "siren                 0.02           0.00      0.00        0.00   0.90   \n",
       "street_music          0.06           0.00      0.00        0.02   0.07   \n",
       "\n",
       "                  street_music  \n",
       "true_row_label                  \n",
       "air_conditioner           0.00  \n",
       "car_horn                  0.00  \n",
       "children_playing          0.02  \n",
       "dog_bark                  0.02  \n",
       "drilling                  0.04  \n",
       "engine_idling             0.00  \n",
       "gun_shot                  0.00  \n",
       "jackhammer                0.00  \n",
       "siren                     0.00  \n",
       "street_music              0.70  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = confusion_matrix(y_true = valid_label, y_pred = valid_predict_label, labels = valid_data.index_to_label)\n",
    "conf = pd.DataFrame(conf, columns = valid_data.index_to_label)\n",
    "conf['true_row_label'] = valid_data.index_to_label\n",
    "conf.set_index('true_row_label', drop = True, inplace = True)\n",
    "conf_perc = round(conf.div(conf.sum(axis=1), axis=0),2)\n",
    "conf_perc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_folder_images(folder):\n",
    "    folder = str(folder)\n",
    "    base_path = \"../downsampled/imagenet_structure/\"\n",
    "    return ImageClassifierDataLoader.from_folder(base_path + folder + \"/train\"), ImageClassifierDataLoader.from_folder(base_path + folder + \"/valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fit_submodel(image_folder_substring, epochs = 10, warmup_steps = 100, batch_size = 24):\n",
    "    train_data, valid_data = train_valid_folder_images(image_folder_substring)\n",
    "    return image_classifier.create(train_data, \n",
    "                                      model_spec=efficientnet_lite4_spec, \n",
    "                                      shuffle = True,\n",
    "                                      epochs = epochs, \n",
    "                                      batch_size = batch_size,\n",
    "                                      warmup_steps = warmup_steps, \n",
    "                                      validation_data = valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['air_conditioner',\n",
       " 'car_horn',\n",
       " 'children_playing',\n",
       " 'dog_bark',\n",
       " 'drilling',\n",
       " 'engine_idling',\n",
       " 'gun_shot',\n",
       " 'jackhammer',\n",
       " 'siren',\n",
       " 'street_music']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.setdiff1d(labels,submodels['engine-air-other'],True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from pathlib import Path  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"list\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-e739f20296df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;34m\"/path\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"list\") to str"
     ]
    }
   ],
   "source": [
    "\"/path\"+os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "motors-other\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_path = Path('../downsampled/imagenet_structure/ensemble/') \n",
    "submodels = {'motors-other': ['air_conditioner', 'engine_idling','drilling', 'jackhammer'],}\n",
    "labels  = ['air_conditioner','car_horn','children_playing',\n",
    "           'dog_bark','drilling','engine_idling','gun_shot','jackhammer','siren','street_music']\n",
    "def move_submodel_files(submodel_folder_name, submodel_class_list):\n",
    "    for d in ['train', 'valid']:\n",
    "        if not os.path.exists(data_path/submodel_folder_name/d/'motors'):\n",
    "            os.mkdir(data_path/submodel_folder_name/d/'motors')\n",
    "        for c in submodel_class_list: #np.setdiff1d(labels,submodel_class_list,True).tolist():\n",
    "            png_files = list(Path(data_path/submodel_folder_name/d/c).glob('*.png'))\n",
    "            for f in png_files:\n",
    "                shutil.move(str(f), str(data_path/submodel_folder_name/d/'motors'))\n",
    "            os.rmdir(data_path/submodel_folder_name/d/c)\n",
    "\n",
    "for k, v in submodels.items():\n",
    "    print(k)\n",
    "    move_submodel_files(k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drill-Jackhammer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Load image with size: 1780, num_label: 2, labels: drilling, jackhammer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Load image with size: 1780, num_label: 2, labels: drilling, jackhammer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Load image with size: 220, num_label: 2, labels: drilling, jackhammer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Load image with size: 220, num_label: 2, labels: drilling, jackhammer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hub_keras_layer_v1v2_1 (HubK (None, 1280)              11837936  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 2562      \n",
      "=================================================================\n",
      "Total params: 11,840,498\n",
      "Trainable params: 2,562\n",
      "Non-trainable params: 11,837,936\n",
      "_________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:Retraining the models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Retraining the models...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 74 steps, validate for 9 steps\n",
      "Epoch 1/20\n",
      "74/74 [==============================] - 37s 504ms/step - loss: 0.6056 - accuracy: 0.6886 - val_loss: 0.4489 - val_accuracy: 0.8889\n",
      "Epoch 2/20\n",
      "74/74 [==============================] - 32s 432ms/step - loss: 0.4964 - accuracy: 0.7889 - val_loss: 0.3884 - val_accuracy: 0.8704\n",
      "Epoch 3/20\n",
      "74/74 [==============================] - 32s 432ms/step - loss: 0.4630 - accuracy: 0.8294 - val_loss: 0.4202 - val_accuracy: 0.8796\n",
      "Epoch 4/20\n",
      "74/74 [==============================] - 32s 432ms/step - loss: 0.4315 - accuracy: 0.8615 - val_loss: 0.3955 - val_accuracy: 0.8704\n",
      "Epoch 5/20\n",
      "74/74 [==============================] - 32s 432ms/step - loss: 0.4311 - accuracy: 0.8547 - val_loss: 0.3973 - val_accuracy: 0.8519\n",
      "Epoch 6/20\n",
      "74/74 [==============================] - 32s 433ms/step - loss: 0.4194 - accuracy: 0.8682 - val_loss: 0.4045 - val_accuracy: 0.8889\n",
      "Epoch 7/20\n",
      "74/74 [==============================] - 32s 437ms/step - loss: 0.4221 - accuracy: 0.8587 - val_loss: 0.3855 - val_accuracy: 0.8796\n",
      "Epoch 8/20\n",
      "74/74 [==============================] - 32s 438ms/step - loss: 0.4007 - accuracy: 0.8812 - val_loss: 0.4009 - val_accuracy: 0.8657\n",
      "Epoch 9/20\n",
      "74/74 [==============================] - 32s 436ms/step - loss: 0.4035 - accuracy: 0.8671 - val_loss: 0.4108 - val_accuracy: 0.8611\n",
      "Epoch 10/20\n",
      "74/74 [==============================] - 34s 466ms/step - loss: 0.3991 - accuracy: 0.8829 - val_loss: 0.3972 - val_accuracy: 0.8704\n",
      "Epoch 11/20\n",
      "74/74 [==============================] - 33s 444ms/step - loss: 0.3939 - accuracy: 0.8812 - val_loss: 0.3936 - val_accuracy: 0.8750\n",
      "Epoch 12/20\n",
      "74/74 [==============================] - 33s 445ms/step - loss: 0.3904 - accuracy: 0.8840 - val_loss: 0.3916 - val_accuracy: 0.8981\n",
      "Epoch 13/20\n",
      "74/74 [==============================] - 33s 446ms/step - loss: 0.3835 - accuracy: 0.8947 - val_loss: 0.4054 - val_accuracy: 0.8750\n",
      "Epoch 14/20\n",
      "74/74 [==============================] - 32s 433ms/step - loss: 0.3839 - accuracy: 0.8896 - val_loss: 0.4224 - val_accuracy: 0.8472\n",
      "Epoch 15/20\n",
      "74/74 [==============================] - 32s 431ms/step - loss: 0.3733 - accuracy: 0.9037 - val_loss: 0.4133 - val_accuracy: 0.8704\n",
      "Epoch 16/20\n",
      "74/74 [==============================] - 34s 455ms/step - loss: 0.3782 - accuracy: 0.9043 - val_loss: 0.4165 - val_accuracy: 0.8611\n",
      "Epoch 17/20\n",
      "74/74 [==============================] - 32s 436ms/step - loss: 0.3815 - accuracy: 0.8936 - val_loss: 0.4001 - val_accuracy: 0.8796\n",
      "Epoch 18/20\n",
      "74/74 [==============================] - 32s 437ms/step - loss: 0.3828 - accuracy: 0.8919 - val_loss: 0.3894 - val_accuracy: 0.8935\n",
      "Epoch 19/20\n",
      "74/74 [==============================] - 32s 435ms/step - loss: 0.3750 - accuracy: 0.9065 - val_loss: 0.3915 - val_accuracy: 0.8935\n",
      "Epoch 20/20\n",
      "74/74 [==============================] - 32s 438ms/step - loss: 0.3740 - accuracy: 0.8947 - val_loss: 0.3986 - val_accuracy: 0.8796\n"
     ]
    }
   ],
   "source": [
    "model_drill_jackhammer-other = create_fit_submodel('ensemble/drilling-jackhammer-other', epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/drill_jackhammer_e20\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/drill_jackhammer_e20\\assets\n"
     ]
    }
   ],
   "source": [
    "model_drill_jackhammer.model.save('models/ensemble/drill_jackhammer_e15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 6s 911ms/step - loss: 0.4095 - accuracy: 0.8591\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_drill_jackhammer.evaluate(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Export to tflite model in ./models/UrbanDrillJackhammerEfficientNet.tflite.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Export to tflite model in ./models/UrbanDrillJackhammerEfficientNet.tflite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saved labels in ./models/UrbanDrillJackhammerEfficientNet_labels.txt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saved labels in ./models/UrbanDrillJackhammerEfficientNet_labels.txt.\n"
     ]
    }
   ],
   "source": [
    "model_path_prefix = './models/UrbanDrillJackhammerEfficientNet'\n",
    "model_drill_jackhammer.export(model_path_prefix+'.tflite', model_path_prefix+'_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_predicts = model_drill_jackhammer.predict_top_k(valid_data)\n",
    "valid_label = [valid_data.index_to_label[label.numpy()] for i, (image, label) in enumerate(valid_data.dataset.take(len(valid_predicts)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_predict_label = [i[0][0] for i in valid_predicts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    drilling       0.95      0.78      0.86       100\n",
      "  jackhammer       0.84      0.97      0.90       120\n",
      "\n",
      "    accuracy                           0.88       220\n",
      "   macro avg       0.90      0.87      0.88       220\n",
      "weighted avg       0.89      0.88      0.88       220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#e20\n",
    "print(classification_report(y_true = valid_label, y_pred = valid_predict_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engine-Air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Load image with size: 1804, num_label: 2, labels: air_conditioner, engine_idling.\n",
      "INFO:tensorflow:Load image with size: 196, num_label: 2, labels: air_conditioner, engine_idling.\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data = train_valid_folder_images('ensemble/engine-air')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\audrey\\anaconda3\\envs\\robotics\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\audrey\\anaconda3\\envs\\robotics\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hub_keras_layer_v1v2 (HubKer (None, 1280)              11837936  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 2562      \n",
      "=================================================================\n",
      "Total params: 11,840,498\n",
      "Trainable params: 2,562\n",
      "Non-trainable params: 11,837,936\n",
      "_________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:Retraining the models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Retraining the models...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 75 steps\n",
      "Epoch 1/10\n",
      "75/75 [==============================] - 37s 488ms/step - loss: 0.5646 - accuracy: 0.7311\n",
      "Epoch 2/10\n",
      "75/75 [==============================] - 29s 387ms/step - loss: 0.4646 - accuracy: 0.8244\n",
      "Epoch 3/10\n",
      "75/75 [==============================] - 29s 388ms/step - loss: 0.4450 - accuracy: 0.8417\n",
      "Epoch 4/10\n",
      "75/75 [==============================] - 29s 387ms/step - loss: 0.4308 - accuracy: 0.8517\n",
      "Epoch 5/10\n",
      "75/75 [==============================] - 29s 387ms/step - loss: 0.4088 - accuracy: 0.8683\n",
      "Epoch 6/10\n",
      "75/75 [==============================] - 29s 388ms/step - loss: 0.4016 - accuracy: 0.8744\n",
      "Epoch 7/10\n",
      "75/75 [==============================] - 29s 388ms/step - loss: 0.4075 - accuracy: 0.8761\n",
      "Epoch 8/10\n",
      "75/75 [==============================] - 29s 387ms/step - loss: 0.4001 - accuracy: 0.8733\n",
      "Epoch 9/10\n",
      "75/75 [==============================] - 29s 388ms/step - loss: 0.3967 - accuracy: 0.8733\n",
      "Epoch 10/10\n",
      "75/75 [==============================] - 29s 388ms/step - loss: 0.3873 - accuracy: 0.8850\n"
     ]
    }
   ],
   "source": [
    "model_engine_air = image_classifier.create(train_data, \n",
    "                                      model_spec=efficientnet_lite4_spec, \n",
    "                                      shuffle = True,\n",
    "                                      batch_size = 24,\n",
    "                                      warmup_steps = 100, \n",
    "                                      epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 6s 902ms/step - loss: 0.5122 - accuracy: 0.7857\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_engine_air.evaluate(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Export to tflite model in ./models/UrbanEngineAirEfficientNet.tflite.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Export to tflite model in ./models/UrbanEngineAirEfficientNet.tflite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saved labels in ./models/UrbanEngineAirEfficientNet_labels.txt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saved labels in ./models/UrbanEngineAirEfficientNet_labels.txt.\n"
     ]
    }
   ],
   "source": [
    "model_path_prefix = './models/UrbanEngineAirEfficientNet'\n",
    "model_engine_air.export(model_path_prefix+'.tflite', model_path_prefix+'_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_predicts = model_engine_air.predict_top_k(valid_data)\n",
    "valid_label = [valid_data.index_to_label[label.numpy()] for i, (image, label) in enumerate(valid_data.dataset.take(len(valid_predicts)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_predict_label = [i[0][0] for i in valid_predicts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "air_conditioner       0.88      0.67      0.76       100\n",
      "  engine_idling       0.72      0.91      0.81        96\n",
      "\n",
      "       accuracy                           0.79       196\n",
      "      macro avg       0.80      0.79      0.78       196\n",
      "   weighted avg       0.80      0.79      0.78       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#e20\n",
    "print(classification_report(y_true = valid_label, y_pred = valid_predict_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Load image with size: 4275, num_label: 6, labels: car_horn, children_playing, dog_bark, gun_shot, siren, street_music.\n",
      "INFO:tensorflow:Load image with size: 457, num_label: 6, labels: car_horn, children_playing, dog_bark, gun_shot, siren, street_music.\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data = train_valid_folder_images('ensemble/other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\audrey\\anaconda3\\envs\\robotics\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\audrey\\anaconda3\\envs\\robotics\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hub_keras_layer_v1v2 (HubKer (None, 1280)              11837936  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 7686      \n",
      "=================================================================\n",
      "Total params: 11,845,622\n",
      "Trainable params: 7,686\n",
      "Non-trainable params: 11,837,936\n",
      "_________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:Retraining the models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Retraining the models...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 178 steps\n",
      "Epoch 1/10\n",
      "178/178 [==============================] - 77s 431ms/step - loss: 1.0710 - accuracy: 0.6847\n",
      "Epoch 2/10\n",
      "178/178 [==============================] - 70s 391ms/step - loss: 0.8695 - accuracy: 0.8031\n",
      "Epoch 3/10\n",
      "178/178 [==============================] - 71s 400ms/step - loss: 0.8283 - accuracy: 0.8165\n",
      "Epoch 4/10\n",
      "178/178 [==============================] - 70s 394ms/step - loss: 0.8023 - accuracy: 0.8345\n",
      "Epoch 5/10\n",
      "178/178 [==============================] - 70s 394ms/step - loss: 0.7927 - accuracy: 0.8481\n",
      "Epoch 6/10\n",
      "178/178 [==============================] - 70s 396ms/step - loss: 0.7801 - accuracy: 0.8507\n",
      "Epoch 7/10\n",
      "178/178 [==============================] - 70s 391ms/step - loss: 0.7670 - accuracy: 0.8521\n",
      "Epoch 8/10\n",
      "178/178 [==============================] - 70s 393ms/step - loss: 0.7645 - accuracy: 0.8518\n",
      "Epoch 9/10\n",
      "178/178 [==============================] - 70s 392ms/step - loss: 0.7526 - accuracy: 0.8694\n",
      "Epoch 10/10\n",
      "178/178 [==============================] - 71s 401ms/step - loss: 0.7517 - accuracy: 0.8624\n"
     ]
    }
   ],
   "source": [
    "model_other = image_classifier.create(train_data, \n",
    "                                      model_spec=efficientnet_lite4_spec, \n",
    "                                      shuffle = True,\n",
    "                                      batch_size = 24,\n",
    "                                      warmup_steps = 100, \n",
    "                                      epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 12s 775ms/step - loss: 0.7071 - accuracy: 0.8884\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_other.evaluate(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Export to tflite model in ./models/UrbanOtherEfficientNet.tflite.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Export to tflite model in ./models/UrbanOtherEfficientNet.tflite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saved labels in ./models/UrbanOtherEfficientNet_labels.txt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saved labels in ./models/UrbanOtherEfficientNet_labels.txt.\n"
     ]
    }
   ],
   "source": [
    "model_path_prefix = './models/UrbanOtherEfficientNet'\n",
    "model_other.export(model_path_prefix+'.tflite', model_path_prefix+'_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_predicts = model_other.predict_top_k(valid_data)\n",
    "valid_label = [valid_data.index_to_label[label.numpy()] for i, (image, label) in enumerate(valid_data.dataset.take(len(valid_predicts)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_predict_label = [i[0][0] for i in valid_predicts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "        car_horn       0.89      0.92      0.90        36\n",
      "children_playing       0.82      0.93      0.87       100\n",
      "        dog_bark       0.92      0.91      0.91       100\n",
      "        gun_shot       0.91      0.91      0.91        35\n",
      "           siren       0.87      0.92      0.89        86\n",
      "    street_music       0.95      0.78      0.86       100\n",
      "\n",
      "        accuracy                           0.89       457\n",
      "       macro avg       0.89      0.89      0.89       457\n",
      "    weighted avg       0.89      0.89      0.89       457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#e20\n",
    "print(classification_report(y_true = valid_label, y_pred = valid_predict_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Tflite models & Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class urban_ensemble():\n",
    "    def __init__(tflite_path_dict):\n",
    "        self.path_dict = tflite_path_dict\n",
    "        \n",
    "    def _load_tflite_model(model_path, label_path):\n",
    "        \n",
    "        with tf.io.gfile.GFile('model_path', 'rb') as f:\n",
    "            model_content = f.read()\n",
    "        with tf.io.gfile.GFile('label_path', 'r') as f:\n",
    "            label_names = f.read().split('\\n')\n",
    "\n",
    "        interpreter = tf.lite.Interpreter(model_content = model_content)\n",
    "        input_index = interpreter.get_input_details()[0]['index']\n",
    "        output = interpreter.tensor(interpreter.get_output_details()[0][\"index\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "imtest = Image.open('7061-6-0-0.png')\n",
    "imtest = np.asarray(imtest)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow_core.lite' from 'c:\\\\users\\\\audrey\\\\anaconda3\\\\envs\\\\robotics\\\\lib\\\\site-packages\\\\tensorflow_core\\\\lite\\\\__init__.py'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.lite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(path):\n",
    "  with open(path, 'r') as f:\n",
    "    return {i: line.strip() for i, line in enumerate(f.readlines())}\n",
    "\n",
    "\n",
    "def set_input_tensor(interpreter, image):\n",
    "    tensor_index = interpreter.get_input_details()[0]['index']\n",
    "    input_tensor = interpreter.tensor(tensor_index)()[0]\n",
    "    input_tensor[:, :] = image\n",
    "\n",
    "\n",
    "def classify_image(interpreter, image_array, top_k=1):\n",
    "    \"\"\"Returns a sorted array of classification results.\"\"\"\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_array)\n",
    "    interpreter.invoke()\n",
    "    output_details = interpreter.get_output_details()[0]\n",
    "    output = np.squeeze(interpreter.get_tensor(output_details['index']))\n",
    "\n",
    "    # If the model is quantized (uint8 data), then dequantize the results\n",
    "    if output_details['dtype'] == np.uint8:\n",
    "        scale, zero_point = output_details['quantization']\n",
    "        output = scale * (output - zero_point)\n",
    "\n",
    "    ordered = np.argpartition(-output, top_k)\n",
    "    return [(i, output[i]) for i in ordered[:top_k]]\n",
    "\n",
    "##################################################\n",
    "class UrbanInterpreter():\n",
    "    def __init__(model_dict):\n",
    "        self.model_files_dict = model_files_dict\n",
    "            \n",
    "    def _read_tflite_model(model_path):\n",
    "        with tf.io.gfile.GFile(model_path, 'rb') as f:\n",
    "            return f.read()\n",
    "\n",
    "    def _read_tflite_labels(label_path)\n",
    "        with tf.io.gfile.GFile(label_path, 'r') as f:\n",
    "            return f.read().split('\\n')\n",
    "        \n",
    "    def _initialize_interpreter(model_files, label_names):\n",
    "        model_content = _read_tflite_model(model_files(['tflite_file']))\n",
    "        label_names = _read_tflite_labels(model_files(['labels']))\n",
    "        interpreter = tf.lite.Interpreter(model_content= model_content)\n",
    "        interpreter.allocate_tensors()\n",
    "        input_index = interpreter.get_input_details()[0]['index']\n",
    "        output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "        return interpreter\n",
    "\n",
    "def urban_ensemble_predict(model_dict, image_path):\n",
    "    \n",
    "    \n",
    "    labels= load_labels(labels)\n",
    "    interpreter = tf.lite.Interpreter(model)\n",
    "    interpreter.allocate_tensors()\n",
    "    _, height, width, _ = interpreter.get_input_details()[0]['shape']\n",
    "\n",
    "    image = np.asarray(Image.open(image_path).resize((width, height)))/255\n",
    "        start_time = time.time()\n",
    "        results = classify_image(interpreter, image)\n",
    "        label_id, prob = results[0]\n",
    "    finally:\n",
    "      camera.stop_preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read TensorFlow Lite model from TensorFlow Lite file.\n",
    "with tf.io.gfile.GFile('flower_classifier.tflite', 'rb') as f:\n",
    "  model_content = f.read()\n",
    "\n",
    "# Read label names from label file.\n",
    "with tf.io.gfile.GFile('flower_labels.txt', 'r') as f:\n",
    "  label_names = f.read().split('\\n')\n",
    "\n",
    "# Initialze TensorFlow Lite inpterpreter.\n",
    "interpreter = tf.lite.Interpreter(model_content=model_content)\n",
    "interpreter.allocate_tensors()\n",
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "output = interpreter.tensor(interpreter.get_output_details()[0][\"index\"])\n",
    "\n",
    "# Run predictions on each test image data and calculate accuracy.\n",
    "accurate_count = 0\n",
    "for i, (image, label) in enumerate(test_data.dataset):\n",
    "    # Pre-processing should remain the same. Currently, just normalize each pixel value and resize image according to the model's specification.\n",
    "    image, _ = model.preprocess(image, label)\n",
    "    # Add batch dimension and convert to float32 to match with the model's input\n",
    "    # data format.\n",
    "    image = tf.expand_dims(image, 0).numpy()\n",
    "\n",
    "    # Run inference.\n",
    "    interpreter.set_tensor(input_index, image)\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Post-processing: remove batch dimension and find the label with highest\n",
    "    # probability.\n",
    "    predict_label = np.argmax(output()[0])\n",
    "    # Get label name with label index.\n",
    "    predict_label_name = label_names[predict_label]\n",
    "\n",
    "    accurate_count += (predict_label == label.numpy())\n",
    "\n",
    "accuracy = accurate_count * 1.0 / test_data.size\n",
    "print('TensorFlow Lite model accuracy = %.4f' % accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
